{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fcastellanosp/MINE-4210_202420_ADL/blob/main/Laboratorios/Laboratorio%204/MINE4210_ADL2024_Lab4_S2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znKNaJnn_ipc"
      },
      "source": [
        "![Logo ADL](https://github.com/fcastellanosp/MINE-4210_202420_ADL/blob/main/Laboratorios/logo_adl.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkCYoS7vchGU"
      },
      "source": [
        "\n",
        "# **Laboratorio 4 - Sesión 2**\n",
        "## **Transformers y BERT**\n",
        "\n",
        "## **Tabla de Contenido**\n",
        "\n",
        "[Contexto y objetivos.](#scrollTo=KYa62M9t8wdQ&line=8&uniqifier=1)<br>\n",
        "[0. Importación de librerías.](#scrollTo=cbrYuu93RJvA&line=1&uniqifier=1)<br>\n",
        "[1. Entendimiento y preparación de los datos.](#scrollTo=k4aTtfgWSC7Y&line=1&uniqifier=1)<br>\n",
        "[2. Modelamiento y evaluación.](#scrollTo=1Okx5TkdXp08&line=1&uniqifier=1)<br>\n",
        "[3. Preguntas.](#scrollTo=LXfiOnYIxA3n&line=1&uniqifier=1)<br>\n",
        "\n",
        "**Tutores**\n",
        "- Fabián Camilo Castellanos.\n",
        "- Nicolás Tibatá Castañeda.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYa62M9t8wdQ"
      },
      "source": [
        "## Contexto y Objetivos\n",
        "\n",
        "**Problema**\n",
        "- Se requiere realizar el análisis de sentimientos de un conjunto de frases del sector financiero como parte de la evaluación del sentimiento del mercado y la reputación de empresas, con el objetivo de tomar decisiones de inversión informadas.\n",
        "\n",
        "**Objetivos**\n",
        "- Construir una Red Neuronal basada en una arquitectura Transformers para llevar a cabo un análisis de sentimientos, ejemplificando así la aplicación de modelos de procesamiento del lenguaje natural.\n",
        "- Conocer como implementar una red neuronal de NLP con transformers tanto en Keras como en Huggingface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbrYuu93RJvA"
      },
      "source": [
        "## 0. Importación de Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjJLC_3BdLEG",
        "outputId": "b59ed3f5-76e4-4d6a-b1ef-a3a94c042912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.7/479.7 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.36 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "albumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "pydantic 2.9.2 requires typing-extensions>=4.6.1; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.23.4 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "torch 2.5.0+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "typeguard 4.3.0 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner -q\n",
        "!pip install transformers -q\n",
        "!pip install \"tf-models-official==2.13.*\" -q\n",
        "# El '-q' hace referencia a 'quiet'. Por lo tanto el output de los paquetes no se muestra completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ1xHA9zXp00",
        "outputId": "9d266fde-fab0-4125-84e4-d5586ebcb3b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.13.1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Dropout, LSTM, Flatten\n",
        "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from google.colab import files\n",
        "\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4aTtfgWSC7Y"
      },
      "source": [
        "## 1. Entendimiento y preparación de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrU7KURhTYBf"
      },
      "source": [
        "Una empresa del sector financiero requiere realizar el análisis de sentimientos de un conjunto de frases del sector para poder hacer evaluación del sentimiento del mercado y la reputación de las empresas.\n",
        "\n",
        "En primer lugar, este análisis proporciona información valiosa para la toma de decisiones de inversión. Al evaluar el sentimiento del mercado a partir de las opiniones y comentarios expresados en las frases, los inversores pueden tomar decisiones más informadas. Esto permite identificar tendencias emergentes, detectar posibles riesgos y oportunidades, y ajustar sus carteras de inversión de acuerdo a la dinámica del mercado.\n",
        "\n",
        "Los datos se toman de https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis\n",
        "\n",
        "Puedes ver [aquí](https://www.kaggle.com/discussions/general/74235) sobre cómo cargar datos directamente de kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "MeHWQMupmqCO",
        "outputId": "06eecd91-7414-475d-a5ff-66585036a024"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8256f9cd-02d3-45b5-a3b2-123e60dea493\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8256f9cd-02d3-45b5-a3b2-123e60dea493\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "rm: cannot remove '/root/.kaggle': No such file or directory\n",
            "ref                                                          title                                           size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "-----------------------------------------------------------  ---------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "valakhorasani/mobile-device-usage-and-user-behavior-dataset  Mobile Device Usage and User Behavior Dataset   11KB  2024-09-28 20:21:12          10632        198  1.0              \n",
            "lainguyn123/student-performance-factors                      Student Performance Factors                     94KB  2024-09-02 10:53:57          39353        681  1.0              \n",
            "valakhorasani/gym-members-exercise-dataset                   Gym Members Exercise Dataset                    22KB  2024-10-06 11:27:38           5409         96  1.0              \n",
            "umeradnaan/prediction-of-disaster-management-in-2024         Forecasting Disaster Management in 2024        293KB  2024-10-16 10:38:25            932         23  1.0              \n",
            "ankulsharma150/netflix-data-analysis                         Netflix Data Analysis                            1MB  2024-10-15 08:02:26           2119         31  1.0              \n",
            "aravinii/house-price-prediction-treated-dataset              House Price Prediction Treated Dataset         279KB  2024-10-22 01:17:46           1542         26  1.0              \n",
            "patricklford/largest-companies-analysis-worldwide            World Top Companies: Key Financial Analysis      1MB  2024-10-01 14:11:29           1847         29  1.0              \n",
            "gcreatives/impact-of-covid-19-on-working-professionals       Impact of COVID-19 on Working Professionals    239KB  2024-10-17 11:10:17           1833         33  0.9411765        \n",
            "abdulszz/spotify-most-streamed-songs                         Spotify Most Streamed Songs                     60KB  2024-09-07 18:23:14          15770        201  1.0              \n",
            "arpitsinghaiml/u-s-crime-dataset                             U.S. Crime Dataset (Jan. 2020 - Sept. 2024)     48MB  2024-10-11 05:11:00           1006         24  0.9411765        \n",
            "mohamedyosef101/2024-olympics-medals-and-economic-status     2024 Olympics Medals and Economic status         2KB  2024-10-13 12:39:58           2133         28  1.0              \n",
            "ravi20076/janestreetpublicv1                                 JaneStreet|Public|V1                           133MB  2024-10-16 11:17:01             99         17  1.0              \n",
            "jakubkhalponiak/phones-2024                                  Phones 2024                                      1MB  2024-10-18 12:57:22            737         30  0.9411765        \n",
            "muhammadroshaanriaz/the-rise-of-artificial-intelligence      The Rise Of Artificial Intelligence            1009B  2024-10-14 19:31:10           1635         31  1.0              \n",
            "iamtanmayshukla/lung-cancer-data                             Lung Cancer Data                                 2KB  2024-10-18 01:52:15            528         25  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                        Melbourne Housing Snapshot                     451KB  2018-06-05 12:52:24         160596       1539  0.7058824        \n",
            "assemelqirsh/covid19-dataset                                 Covid19_Dataset                                 10MB  2024-10-01 11:30:44           1872         27  1.0              \n",
            "jvanark/nvidia-daily-stock-price-data                        Nvidia Daily Stock Price Data 📈                120KB  2024-09-25 10:06:21           1286         27  1.0              \n",
            "mafzal19/electric-vehicle-sales-by-state-in-india            Electric Vehicle Sales by State in India       453KB  2024-10-11 18:59:45           1804         29  1.0              \n",
            "sachinkumar62/phone-price-prediction-dataset                 Phone Price Prediction Dataset                  13MB  2024-10-06 17:39:10            961         31  1.0              \n"
          ]
        }
      ],
      "source": [
        "files.upload() # Cargamos el Kaggle.json (API)\n",
        "\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets list #Correr este comando verifica que está bien montado el driver de kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82D2nWjEc_DO",
        "outputId": "f830558f-828a-48ec-e650-b95656e1027b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis\n",
            "License(s): CC0-1.0\n",
            "Downloading financial-sentiment-analysis.zip to /content\n",
            "100% 276k/276k [00:00<00:00, 624kB/s]\n",
            "100% 276k/276k [00:00<00:00, 623kB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download sbhatti/financial-sentiment-analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAonWTnOdK_F",
        "outputId": "171e292a-b7ff-445f-f551-ae7c40e31c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Archive:  financial-sentiment-analysis.zip\n",
            "  inflating: /content/financial-sentiment-analysis/data.csv  \n"
          ]
        }
      ],
      "source": [
        "ROOT_DIR = '/content'\n",
        "DATASET_NAME = 'financial-sentiment-analysis'\n",
        "\n",
        "%cd {ROOT_DIR}\n",
        "!unzip {DATASET_NAME}.zip -d {ROOT_DIR}/{DATASET_NAME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "CEKEC0uBjFJq",
        "outputId": "222c0f70-87de-4d8f-c4b5-dbb863c808b1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5842,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5322,\n        \"samples\": [\n          \"It is now the leading private road ambulance service company in Finland .\",\n          \"Finnish silicon wafers manufacturer Okmetic Oyj said it swung to a net profit of 4.9 mln euro $ 6.3 mln in the first nine months of 2006 from a net loss of 1.8 mln euro $ 2.3 mln a year earlier .\",\n          \"$GILD  is expanding its research facilities...keeping up with the pace of innovation  https://t.co/uOE7FJ4LOP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"negative\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bdf025df-3d08-4abd-ab6e-680729d7339a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5837</th>\n",
              "      <td>RISING costs have forced packaging producer Hu...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5838</th>\n",
              "      <td>Nordic Walking was first used as a summer trai...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5839</th>\n",
              "      <td>According shipping company Viking Line , the E...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5840</th>\n",
              "      <td>In the building and home improvement trade , s...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5841</th>\n",
              "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5842 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdf025df-3d08-4abd-ab6e-680729d7339a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bdf025df-3d08-4abd-ab6e-680729d7339a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bdf025df-3d08-4abd-ab6e-680729d7339a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-be999560-255f-446a-9411-844effd1ccb7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be999560-255f-446a-9411-844effd1ccb7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-be999560-255f-446a-9411-844effd1ccb7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_598076a5-4eae-440a-b078-5e85d74941c8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_598076a5-4eae-440a-b078-5e85d74941c8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               Sentence Sentiment\n",
              "0     The GeoSolutions technology will leverage Bene...  positive\n",
              "1     $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
              "2     For the last quarter of 2010 , Componenta 's n...  positive\n",
              "3     According to the Finnish-Russian Chamber of Co...   neutral\n",
              "4     The Swedish buyout firm has sold its remaining...   neutral\n",
              "...                                                 ...       ...\n",
              "5837  RISING costs have forced packaging producer Hu...  negative\n",
              "5838  Nordic Walking was first used as a summer trai...   neutral\n",
              "5839  According shipping company Viking Line , the E...   neutral\n",
              "5840  In the building and home improvement trade , s...   neutral\n",
              "5841  HELSINKI AFX - KCI Konecranes said it has won ...  positive\n",
              "\n",
              "[5842 rows x 2 columns]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(f'{ROOT_DIR}/{DATASET_NAME}/data.csv')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nAgHblmjUjO",
        "outputId": "91ee6f85-6242-4cfd-c58d-390aa4466b6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5842 entries, 0 to 5841\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Sentence   5842 non-null   object\n",
            " 1   Sentiment  5842 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 91.4+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rVGm9dVB6ZJ"
      },
      "source": [
        "Realizamos la revisión de texto para cada uno de los sentimientos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K32IArB3cihD",
        "outputId": "ff67c2ac-9bca-457c-eb63-7c379585bd70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment: positive\n",
            "Sentence: The GeoSolutions technology will leverage Benefon 's GPS solutions by providing Location Based Search Technology , a Communities Platform , location relevant multimedia content and a new and powerful commercial model .\n",
            "\n",
            "Sentiment: negative\n",
            "Sentence: $ESI on lows, down $1.50 to $2.50 BK a real possibility\n",
            "\n",
            "Sentiment: neutral\n",
            "Sentence: According to the Finnish-Russian Chamber of Commerce , all the major construction companies of Finland are operating in Russia .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "unique_sentiments = data['Sentiment'].unique()\n",
        "\n",
        "for sentiment in unique_sentiments:\n",
        "    row = data[data['Sentiment'] == sentiment].iloc[0]  # Obtener la primera fila con el valor de sentimiento específico\n",
        "    print(\"Sentiment:\", sentiment)\n",
        "    print(\"Sentence:\", row['Sentence'])\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "aZ1BmCb6gtfk",
        "outputId": "7ad2feba-46e3-4b94-be34-5c4c64d1492a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>3130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>1852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "Sentiment\n",
              "neutral     3130\n",
              "positive    1852\n",
              "negative     860\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"Sentiment\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HILVZL3Hwl_G"
      },
      "source": [
        "Ahora vamos a pasar el sentimiento (clase) a un valor entero usando LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_imuGun6nlEX",
        "outputId": "8b99cd90-64be-4d06-9495-08a130614924"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valor numérico: 0, Etiqueta original: negative\n",
            "Valor numérico: 1, Etiqueta original: neutral\n",
            "Valor numérico: 2, Etiqueta original: positive\n"
          ]
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "data['Sentiment'] = label_encoder.fit_transform(data['Sentiment'])\n",
        "\n",
        "etiquetas_unicas = label_encoder.classes_\n",
        "for valor_numerico, etiqueta_original in enumerate(etiquetas_unicas):\n",
        "    print(f'Valor numérico: {valor_numerico}, Etiqueta original: {etiqueta_original}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA7lH4P4wyCQ"
      },
      "source": [
        "Hacemos la división de los conjuntos para entrenamiento, validación y prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "b-xIiI9JStV3",
        "outputId": "0f38e4eb-29ba-4c87-f426-ae2aa0c59f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño de datos de entrenamiento: (3738, 2)\n",
            "Tamaño de datos de validación: (935, 2)\n",
            "Tamaño de datos de prueba: (1169, 2)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 3738,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3523,\n        \"samples\": [\n          \"The business development initiatives in North America are headed by Lynn Shanahan .\",\n          \"Elcoteq has a global network of After Market Service sites which have a long experience in serving Consumer Electronics and Systems Solutions customers .\",\n          \"The Nokia Music Store begins trading on Tuesday , selling singles and albums as well as live music streaming .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-881cf7c9-c107-4440-84c0-51bb417f4dc0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3097</th>\n",
              "      <td>Digia will also set up two subsidiaries , Digi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5048</th>\n",
              "      <td>$BBRY Sierra. Has a great cash balance and imp...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5727</th>\n",
              "      <td>Britain's FTSE gains, Land Securities up after...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>The Finnish company sold its UK operation - co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4265</th>\n",
              "      <td>Russian Media Ventures ' minority shareholder ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>( I&amp;H ) in a move to enhance growth .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2821</th>\n",
              "      <td>In addition , a further 29 employees can be la...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4365</th>\n",
              "      <td>The paper industry 's de-inking sludge , which...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1603</th>\n",
              "      <td>$JE LOOKS like we are bouncing.  Would be nice...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>A survey conducted by Taloustutkimus for Sampo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3738 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-881cf7c9-c107-4440-84c0-51bb417f4dc0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-881cf7c9-c107-4440-84c0-51bb417f4dc0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-881cf7c9-c107-4440-84c0-51bb417f4dc0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-43f4a0fc-4ef8-4f93-9d37-3ba6cbae57dd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43f4a0fc-4ef8-4f93-9d37-3ba6cbae57dd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-43f4a0fc-4ef8-4f93-9d37-3ba6cbae57dd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_89b0473a-0a1f-4cee-9cf5-71ef2da3bac4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_89b0473a-0a1f-4cee-9cf5-71ef2da3bac4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               Sentence  Sentiment\n",
              "3097  Digia will also set up two subsidiaries , Digi...          1\n",
              "5048  $BBRY Sierra. Has a great cash balance and imp...          2\n",
              "5727  Britain's FTSE gains, Land Securities up after...          2\n",
              "185   The Finnish company sold its UK operation - co...          1\n",
              "4265  Russian Media Ventures ' minority shareholder ...          1\n",
              "...                                                 ...        ...\n",
              "326               ( I&H ) in a move to enhance growth .          2\n",
              "2821  In addition , a further 29 employees can be la...          0\n",
              "4365  The paper industry 's de-inking sludge , which...          1\n",
              "1603  $JE LOOKS like we are bouncing.  Would be nice...          2\n",
              "200   A survey conducted by Taloustutkimus for Sampo...          1\n",
              "\n",
              "[3738 rows x 2 columns]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Divide los datos en entrenamiento y prueba\n",
        "train, test = train_test_split(data, test_size=0.2, stratify=data['Sentiment'], random_state=42, shuffle = True)\n",
        "\n",
        "# Ahora divide el conjunto de entrenamiento en entrenamiento y validación\n",
        "train, val = train_test_split(train, test_size=0.2, stratify=train['Sentiment'], random_state=42, shuffle = True)\n",
        "\n",
        "print(\"Tamaño de datos de entrenamiento:\", train.shape)\n",
        "print(\"Tamaño de datos de validación:\", val.shape)\n",
        "print(\"Tamaño de datos de prueba:\", test.shape)\n",
        "\n",
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N2rXPU3xD_g"
      },
      "source": [
        "Revisamos la dristibución de sentimientos del conjunto de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "J9luU-3EPCt3",
        "outputId": "71c90306-48ec-43b9-ad34-4d5ca70b74ba"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a bar plot to visualize the distribution\n",
        "unique, counts = np.unique(train['Sentiment'], return_counts=True)\n",
        "plt.bar(unique, counts)\n",
        "plt.xlabel('Sentiment Category')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Sentiment Categories')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prG1C9Q6w7Wk"
      },
      "source": [
        "Separamos las oraciones y el sentimiento que representan.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "omufr61v2guj",
        "outputId": "e0de251f-d7b0-4534-f7ad-0e945c72fe49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train (3738,)  y_train: (3738,)\n",
            "x_test: (1169,) y_test (1169,)\n",
            "x_val (935,) y_val: (935,)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3097</th>\n",
              "      <td>Digia will also set up two subsidiaries , Digi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5048</th>\n",
              "      <td>$BBRY Sierra. Has a great cash balance and imp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5727</th>\n",
              "      <td>Britain's FTSE gains, Land Securities up after...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>The Finnish company sold its UK operation - co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4265</th>\n",
              "      <td>Russian Media Ventures ' minority shareholder ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>( I&amp;H ) in a move to enhance growth .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2821</th>\n",
              "      <td>In addition , a further 29 employees can be la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4365</th>\n",
              "      <td>The paper industry 's de-inking sludge , which...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1603</th>\n",
              "      <td>$JE LOOKS like we are bouncing.  Would be nice...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>A survey conducted by Taloustutkimus for Sampo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3738 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "3097    Digia will also set up two subsidiaries , Digi...\n",
              "5048    $BBRY Sierra. Has a great cash balance and imp...\n",
              "5727    Britain's FTSE gains, Land Securities up after...\n",
              "185     The Finnish company sold its UK operation - co...\n",
              "4265    Russian Media Ventures ' minority shareholder ...\n",
              "                              ...                        \n",
              "326                 ( I&H ) in a move to enhance growth .\n",
              "2821    In addition , a further 29 employees can be la...\n",
              "4365    The paper industry 's de-inking sludge , which...\n",
              "1603    $JE LOOKS like we are bouncing.  Would be nice...\n",
              "200     A survey conducted by Taloustutkimus for Sampo...\n",
              "Name: Sentence, Length: 3738, dtype: object"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, X_val= train['Sentence'], test['Sentence'], val['Sentence']\n",
        "y_train, y_test, y_val= train['Sentiment'], test['Sentiment'], val['Sentiment']\n",
        "\n",
        "print(\"x_train\", X_train.shape, \" y_train:\", y_train.shape)\n",
        "print(\"x_test:\", X_test.shape, \"y_test\", y_test.shape)\n",
        "print(\"x_val\", X_val.shape, \"y_val:\", y_val.shape)\n",
        "\n",
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLov-CkRwoP9"
      },
      "source": [
        "Una de las ventajas de utilizar transformers es que también incorporan una capa de preprocesamiento de datos, lo que simplifica el proceso para utilizarlos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Okx5TkdXp08"
      },
      "source": [
        "## 2. Modelamiento y evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFUVPNnZnXQh"
      },
      "source": [
        "BERT (Bidirectional Encoder Representations from Transformers) es un tipo de estructura utilizado en la mayoría de casos de NLP, veamos cómo se construye una versión más pequeña que la original:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "q0eRIL0tnqWg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Hiper parámetros\n",
        "block_size = 256 # Máximo número de tokens como input al modelo\n",
        "batch_size = 128 # Tamaño del lote\n",
        "model_dim = 512 # Dimensiones de los embeddings de los tokens\n",
        "heads_num = 8 # Número de cabezas en el mecanismo de atención\n",
        "blocks_num = 3 # Número de bloques de Transformner en el modelo\n",
        "\n",
        "# Usar GPU si está disponible\n",
        "device = 'cpu'\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, head_dim):\n",
        "        # embed_dim son las dimensiones del embedding de los tokens originalmente\n",
        "        # head_dim son las dimensiones del vector resultante del mecanismo de atención\n",
        "        super().__init__()\n",
        "        self.head_dim = head_dim\n",
        "\n",
        "        self.Wq = nn.Linear(embed_dim, head_dim, bias=False) # Matriz para generar la representación Q de los tokens\n",
        "        self.Wk = nn.Linear(embed_dim, head_dim, bias=False) # Matriz para generar la representación K de los tokens\n",
        "        self.Wv = nn.Linear(embed_dim, head_dim, bias=False) # Matriz para generar la representación V de los tokens\n",
        "\n",
        "    def forward(self, x): # x.shape = [batch_size, block_size, embed_dim]\n",
        "        N, T, D = x.shape\n",
        "        # Crear representaciones de los tokens\n",
        "        Q = self.Wq(x) # [N, T, D] @ [D, head_dim] = [N, T, head_dim]\n",
        "        K = self.Wk(x) # [N, T, D] @ [D, head_dim] = [N, T, head_dim]\n",
        "        V = self.Wv(x) # [N, T, D] @ [D, head_dim] = [N, T, head_dim]\n",
        "        # Calcular puntajes de similitud\n",
        "        att_weights = Q @ K.transpose(-1,-2) # [N, T, head_dim] @ [N, head_dim, T] = [N, T, T]\n",
        "        att_weights = att_weights * self.head_dim**-0.5 # Reducir el tamaño de los puntajes de similitud\n",
        "\n",
        "        # Los tokes futuros no se enmascaran, de modo que el modelo ve el contexto completo\n",
        "        # masked_att = att_weights.masked_fill(self.mask[:T,:T] == 0, -torch.inf)\n",
        "\n",
        "        att_weights = torch.nn.functional.softmax(att_weights, dim=2)\n",
        "        # Resultado del mecanismo de atención\n",
        "        weighted_output = att_weights @ V # [N, T, T] @ [N, T, head_dim] = [N, T, head_dim]\n",
        "\n",
        "        return weighted_output\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, heads_num, embed_dim, head_dim) -> None:\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([SelfAttention(embed_dim, head_dim//heads_num) for _ in range(heads_num)])\n",
        "        self.dense = nn.Linear(head_dim, head_dim, bias=False)\n",
        "\n",
        "    def forward(self, x): # x: [batch_size, block_size, emb_dim]\n",
        "        heads = [h(x) for h in self.heads] # [batch_size, block_size, head_dim/heads_num] por cada elemento en la lista\n",
        "        att = torch.concat(heads, dim=-1) # Se concatenan los resultados de cada cabeza para obtener [batch_size, block_size, head_dim]\n",
        "        output = self.dense(att) # [batch_size, block_size, head_dim]\n",
        "        return output\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim) -> None:\n",
        "        super().__init__()\n",
        "        self.dense1 = nn.Linear(in_dim, hidden_dim)\n",
        "        self.dense2 = nn.Linear(hidden_dim, out_dim)\n",
        "\n",
        "    def forward(self, x): # x: [batch_size, block_size, head_dim]\n",
        "        dense1 = F.relu(self.dense1(x)) # [batch_size, block_size, head_dim*4]\n",
        "        output = self.dense2(dense1) # [batch_size, block_size, head_dim]\n",
        "        return output\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, heads_num, model_dim) -> None:\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(heads_num, model_dim, model_dim)\n",
        "        self.ln1 = nn.LayerNorm(model_dim)\n",
        "        self.ffd = FeedForward(model_dim, model_dim*4, model_dim)\n",
        "        self.ln2 = nn.LayerNorm(model_dim)\n",
        "\n",
        "        self.drop1 = nn.Dropout(0.1)\n",
        "        self.drop2 = nn.Dropout(0.1)\n",
        "        self.drop3 = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x): # x: [batch_size, block_size, emb_dim]\n",
        "        att = self.attention(x) # [batch_size, block_size, head_dim], emb_dim y head_dim deben ser iguales para que funcionen las conexiones residuales\n",
        "        att = self.drop1(att)\n",
        "        x = self.ln1(att + x)\n",
        "\n",
        "        ffd = self.ffd(x) # [batch_size, block_size, head_dim]\n",
        "        ffd = self.drop2(ffd)\n",
        "        x = self.ln2(ffd + x)\n",
        "        x = self.drop3(x)\n",
        "        return x # [batch_size, block_size, head_dim]\n",
        "\n",
        "\n",
        "class SimpleBERT(nn.Module):\n",
        "    def __init__(self, vocab_size, model_dim, block_size, blocks_num, heads_num) -> None:\n",
        "        super().__init__()\n",
        "        self.E = nn.Embedding(vocab_size, model_dim)\n",
        "        self.posE = nn.Embedding(block_size, model_dim) # Embedding de posición. Cada posición en el contexto (0 - block_size-1) tiene su propio embedding\n",
        "        self.ln1 = nn.LayerNorm(model_dim)\n",
        "        self.blocks = nn.Sequential(*[Block(heads_num, model_dim) for _ in range(blocks_num)]) # El bloque se repite el número de veces deseado\n",
        "        self.dense = nn.Linear(model_dim, vocab_size, bias=False)\n",
        "\n",
        "        # Regularización\n",
        "        self.drop1 = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x): # x: [batch_size, block_size]\n",
        "        emb1 = self.E(x) # [batch_size, block_size, emb_dim]\n",
        "\n",
        "        # Positional embedding\n",
        "        positions = torch.arange(x.shape[1], device=device) # Se genera un número por cada token que representa su posicion en el contexto (de 0 a block_size-1)\n",
        "        emb2 = self.posE(positions) # [block_size, emb_dim]\n",
        "\n",
        "        emb = emb1 + emb2 # [batch_size, block_size, emb_dim] Se suman los embeddings\n",
        "        emb = self.ln1(emb)\n",
        "        emb = self.drop1(emb)\n",
        "\n",
        "        x = self.blocks(emb) # [batch_size, block_size, head_dim]\n",
        "\n",
        "        self.contextual_embeddings = x # Se guarda el embedding contextual para usarlos más adelante\n",
        "\n",
        "        logits = self.dense(x) # [batch_size, block_size, vocab_size]\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfyJJy1NqBDf"
      },
      "source": [
        "Comparemos el modelo original con el construido:\n",
        "\n",
        "<img src=\"https://github.com/fcastellanosp/MINE-4210_202420_ADL/raw/main/Laboratorios/Laboratorio%204/lab4_s2_image1.png\" alt=\"Original Bert\" width=\"1000\" height=\"600\"/>\n",
        "\n",
        "<img src=\"https://github.com/fcastellanosp/MINE-4210_202420_ADL/raw/main/Laboratorios/Laboratorio%204/lab4_s2_image2.png\" alt=\"Modified Bert\" width=\"1000\" height=\"600\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWS-qDqIv0Ed"
      },
      "source": [
        " Con el código de las siguientes secciones podemos seleccionar uno de los modelos BERT y su correspondiente modelo de preprocesamiento utilizando TensorFlow Hub. Pueden ver más información [aquí](https://huggingface.co/transformers/v3.0.2/model_doc/bert.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKqjjJEK4ja-"
      },
      "source": [
        "### 2.1. Modelo Lambert\n",
        "\n",
        "BERT entrenado con LAMB(Layer-wise Adaptive Moments optimizer for Batch training, un optimizador de gradiente descendente estocástico) y técnicas de RoBERTa (Robustly Optimized BERT Approach)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX7dIro64jbA",
        "outputId": "6da2aca5-e0bd-4b26-e419-5b31a95054d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/lambert_en_uncased_L-24_H-1024_A-16/2\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ],
      "source": [
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/lambert_en_uncased_L-24_H-1024_A-16/2'\n",
        "\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-M1uHxCB4jbB"
      },
      "outputs": [],
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gffZgRoC4jbE"
      },
      "outputs": [],
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_WCJQtts4jbE"
      },
      "outputs": [],
      "source": [
        "# Bert layers\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessing_layer = bert_preprocess_model(text_input)\n",
        "outputs = bert_model(preprocessing_layer)\n",
        "\n",
        "# Neural network layers\n",
        "#l = tf.keras.layers.Dropout(0.1, name=\"dropout\")\n",
        "l = tf.keras.layers.Dense(512, activation='sigmoid', name=\"capaOculta1\")(outputs['pooled_output'])\n",
        "l = tf.keras.layers.Dropout(0.2, name=\"dropout\")(l)\n",
        "l = tf.keras.layers.Dense(3, activation='sigmoid', name=\"output\")(l)\n",
        "\n",
        "# Use inputs and outputs to construct a final model\n",
        "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7xawGofF4jbE"
      },
      "outputs": [],
      "source": [
        "metrics = ['accuracy']\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_V0jdgKTpaL",
        "outputId": "b0cf0a6b-2ab7-4147-f79d-a4357ba7ff19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text (InputLayer)           [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " keras_layer_2 (KerasLayer)  {'input_word_ids': (None,    0         ['text[0][0]']                \n",
            "                             128),                                                                \n",
            "                              'input_mask': (None, 128)                                           \n",
            "                             , 'input_type_ids': (None,                                           \n",
            "                              128)}                                                               \n",
            "                                                                                                  \n",
            " keras_layer_3 (KerasLayer)  {'sequence_output': (None,   3351418   ['keras_layer_2[0][0]',       \n",
            "                              128, 1024),                 89         'keras_layer_2[0][1]',       \n",
            "                              'encoder_outputs': [(None              'keras_layer_2[0][2]']       \n",
            "                             , 128, 1024),                                                        \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024),                                                  \n",
            "                              (None, 128, 1024)],                                                 \n",
            "                              'default': (None, 1024),                                            \n",
            "                              'pooled_output': (None, 1                                           \n",
            "                             024)}                                                                \n",
            "                                                                                                  \n",
            " capaOculta1 (Dense)         (None, 512)                  524800    ['keras_layer_3[0][25]']      \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 512)                  0         ['capaOculta1[0][0]']         \n",
            "                                                                                                  \n",
            " output (Dense)              (None, 3)                    1539      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 335668228 (1.25 GB)\n",
            "Trainable params: 526339 (2.01 MB)\n",
            "Non-trainable params: 335141889 (1.25 GB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjPqVAY64jbE",
        "outputId": "fefd8113-d6bc-4640-f888-3b340787be49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "117/117 [==============================] - 169s 1s/step - loss: 0.8959 - accuracy: 0.5902 - val_loss: 0.8004 - val_accuracy: 0.6396\n",
            "Epoch 2/20\n",
            "117/117 [==============================] - 162s 1s/step - loss: 0.7685 - accuracy: 0.6597 - val_loss: 0.7841 - val_accuracy: 0.6642\n",
            "Epoch 3/20\n",
            "117/117 [==============================] - 151s 1s/step - loss: 0.7229 - accuracy: 0.6814 - val_loss: 0.7731 - val_accuracy: 0.6492\n",
            "Epoch 4/20\n",
            "117/117 [==============================] - 160s 1s/step - loss: 0.6996 - accuracy: 0.6846 - val_loss: 0.7946 - val_accuracy: 0.6503\n",
            "Epoch 5/20\n",
            "117/117 [==============================] - 151s 1s/step - loss: 0.6753 - accuracy: 0.7084 - val_loss: 0.7879 - val_accuracy: 0.6439\n",
            "Epoch 6/20\n",
            "117/117 [==============================] - 160s 1s/step - loss: 0.6717 - accuracy: 0.7012 - val_loss: 0.8133 - val_accuracy: 0.6342\n",
            "Epoch 7/20\n",
            "117/117 [==============================] - 151s 1s/step - loss: 0.6541 - accuracy: 0.7057 - val_loss: 0.7894 - val_accuracy: 0.6652\n",
            "Epoch 8/20\n",
            "117/117 [==============================] - 150s 1s/step - loss: 0.6193 - accuracy: 0.7290 - val_loss: 0.8056 - val_accuracy: 0.6449\n",
            "Epoch 9/20\n",
            "117/117 [==============================] - 161s 1s/step - loss: 0.6068 - accuracy: 0.7338 - val_loss: 0.7993 - val_accuracy: 0.6610\n",
            "Epoch 10/20\n",
            "117/117 [==============================] - 151s 1s/step - loss: 0.5872 - accuracy: 0.7354 - val_loss: 0.7985 - val_accuracy: 0.6684\n",
            "Epoch 11/20\n",
            "117/117 [==============================] - 150s 1s/step - loss: 0.5694 - accuracy: 0.7515 - val_loss: 0.7794 - val_accuracy: 0.6406\n",
            "Epoch 12/20\n",
            "117/117 [==============================] - 161s 1s/step - loss: 0.5565 - accuracy: 0.7560 - val_loss: 0.7849 - val_accuracy: 0.6481\n",
            "Epoch 13/20\n",
            "117/117 [==============================] - 161s 1s/step - loss: 0.5280 - accuracy: 0.7761 - val_loss: 0.8151 - val_accuracy: 0.6471\n",
            "Epoch 14/20\n",
            "117/117 [==============================] - 161s 1s/step - loss: 0.5002 - accuracy: 0.7852 - val_loss: 0.8109 - val_accuracy: 0.6556\n",
            "Epoch 15/20\n",
            "117/117 [==============================] - 161s 1s/step - loss: 0.4857 - accuracy: 0.7911 - val_loss: 0.8989 - val_accuracy: 0.6214\n",
            "Epoch 16/20\n",
            "117/117 [==============================] - 162s 1s/step - loss: 0.4756 - accuracy: 0.7937 - val_loss: 0.8438 - val_accuracy: 0.6321\n",
            "Epoch 17/20\n",
            "117/117 [==============================] - 150s 1s/step - loss: 0.4342 - accuracy: 0.8122 - val_loss: 0.8434 - val_accuracy: 0.6374\n",
            "Epoch 18/20\n",
            "117/117 [==============================] - 150s 1s/step - loss: 0.4237 - accuracy: 0.8184 - val_loss: 0.8526 - val_accuracy: 0.6289\n",
            "Epoch 19/20\n",
            "117/117 [==============================] - 162s 1s/step - loss: 0.3974 - accuracy: 0.8341 - val_loss: 0.8662 - val_accuracy: 0.6406\n",
            "Epoch 20/20\n",
            "117/117 [==============================] - 161s 1s/step - loss: 0.3671 - accuracy: 0.8531 - val_loss: 0.8694 - val_accuracy: 0.6503\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f75717095d0>"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train,\n",
        "          validation_data = (X_val, y_val),\n",
        "          epochs=20,\n",
        "          #callbacks= EarlyStopping(monitor='val_accuracy', patience=4)\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbgCZ8ZzyX_M"
      },
      "source": [
        "**Evaluación**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvQRANXu4jbF",
        "outputId": "9b7d5408-bc5f-42a0-ef44-63e874931e49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "117/117 [==============================] - 120s 1s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.65      0.72       550\n",
            "           1       0.88      0.93      0.91      2003\n",
            "           2       0.94      0.93      0.93      1185\n",
            "\n",
            "    accuracy                           0.89      3738\n",
            "   macro avg       0.87      0.84      0.85      3738\n",
            "weighted avg       0.89      0.89      0.89      3738\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_train)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_train, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x6mrjzf4jbF",
        "outputId": "3f6225ff-d784-4505-e14f-4f9780b3ca1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37/37 [==============================] - 38s 1s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.24      0.28       172\n",
            "           1       0.73      0.81      0.77       626\n",
            "           2       0.71      0.67      0.69       371\n",
            "\n",
            "    accuracy                           0.68      1169\n",
            "   macro avg       0.59      0.57      0.58      1169\n",
            "weighted avg       0.67      0.68      0.67      1169\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW1SiArAFLt_"
      },
      "source": [
        "### 2.2. Modelo distilbert huggingface\n",
        "\n",
        "Es un modelo de lenguaje natural basado en la arquitectura de BERT, pero más pequeño, rápido y económico. Fue propuesto por Hugging Face en 2019. El modelo fue entrenado mediante destilación de BERT base y tiene un 40% menos de parámetros que bert-base-uncased, corre un 60% más rápido y preserva más del 95% del rendimiento de BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPXeOXAg87MO"
      },
      "source": [
        "Para trabajar con los transformes de huggingface se utiliza la librería transformers, en este caso importamos el tokenizador (pro-proceamiento que requiere el transformers y el modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "1AGWsY6XMB5M"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lacaf7K49ebw"
      },
      "source": [
        "Hacemos el preprocesamiento de nuestros conjuntos de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "HVWxaUuFMJtw"
      },
      "outputs": [],
      "source": [
        "# Tokenización\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "X_train = [tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=128) for text in X_train]\n",
        "X_val = [tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=128) for text in X_val]\n",
        "X_test = [tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=128) for text in X_test]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz9h25Mm-L4D"
      },
      "source": [
        "Ahora vamos a hacer un padding, lo cual es una práctica común en el procesamiento de texto para asegurar que todas las secuencias de texto tengan la misma longitud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "E4zMy18ZPx1G"
      },
      "outputs": [],
      "source": [
        "max_sequence_length = max(len(seq) for seq in X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "dtduPJvwQQq6"
      },
      "outputs": [],
      "source": [
        "# Padding\n",
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "X_val = tf.keras.preprocessing.sequence.pad_sequences(X_val, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_sequence_length, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etpCWcJe-dOR"
      },
      "source": [
        "Ahora generamos nuestro modelo a partir del modelo DistilBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPujNIb2OnPO"
      },
      "outputs": [],
      "source": [
        "# Crear el modelo DistilBERT\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Agregar una capa de clasificación explícita\n",
        "classification_layer = tf.keras.layers.Dense(3, activation='softmax')  # 'num_classes' es el número de clases en tu tarea de clasificación\n",
        "\n",
        "# Crear el modelo combinado\n",
        "input_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int32)\n",
        "outputs = model(input_ids)[0]  # Salidas de la capa de logits\n",
        "#outputs = classification_layer(outputs)\n",
        "\n",
        "combined_model = tf.keras.Model(inputs=input_ids, outputs=outputs)\n",
        "\n",
        "# Compilar el modelo\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)  # from_logits=False ya que estamos usando 'softmax' en la capa de clasificación\n",
        "combined_model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY13kumzMQZH",
        "outputId": "16c0c88e-40c4-435c-f6fc-c2a7cd794e53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "234/234 [==============================] - 104s 265ms/step - loss: 0.8140 - accuracy: 0.6220 - val_loss: 0.5969 - val_accuracy: 0.7604\n",
            "Epoch 2/15\n",
            "234/234 [==============================] - 46s 196ms/step - loss: 0.4715 - accuracy: 0.8063 - val_loss: 0.4892 - val_accuracy: 0.7807\n",
            "Epoch 3/15\n",
            "234/234 [==============================] - 47s 202ms/step - loss: 0.3395 - accuracy: 0.8513 - val_loss: 0.5192 - val_accuracy: 0.7679\n",
            "Epoch 4/15\n",
            "234/234 [==============================] - 44s 187ms/step - loss: 0.2554 - accuracy: 0.8745 - val_loss: 0.5045 - val_accuracy: 0.7743\n",
            "Epoch 5/15\n",
            "234/234 [==============================] - 47s 201ms/step - loss: 0.2049 - accuracy: 0.8975 - val_loss: 0.5405 - val_accuracy: 0.7775\n"
          ]
        }
      ],
      "source": [
        "# Entrenamiento\n",
        "history = combined_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=15,\n",
        "    batch_size=16,\n",
        "    callbacks= EarlyStopping(monitor='val_accuracy', patience=3)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoKAkNJZ5iaH"
      },
      "source": [
        "**Evaluación**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB0_DLFeNI0m",
        "outputId": "4dec66a6-4518-4626-fddd-889b6ceb63f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37/37 [==============================] - 5s 118ms/step - loss: 0.5270 - accuracy: 0.7716\n",
            "Loss: 0.5269625782966614\n",
            "Accuracy: 0.7715996503829956\n"
          ]
        }
      ],
      "source": [
        "# Evaluación\n",
        "results = combined_model.evaluate(X_test, y_test)\n",
        "print(\"Loss:\", results[0])\n",
        "print(\"Accuracy:\", results[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9ZxzDfe4HTn",
        "outputId": "c1d34ac7-64ed-416a-ff2c-66659ebc7fba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "117/117 [==============================] - 17s 113ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.98      0.78       550\n",
            "           1       0.99      0.85      0.92      2003\n",
            "           2       1.00      0.99      0.99      1185\n",
            "\n",
            "    accuracy                           0.92      3738\n",
            "   macro avg       0.88      0.94      0.90      3738\n",
            "weighted avg       0.94      0.92      0.92      3738\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = combined_model.predict(X_train)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_train, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bimjvGcx4P84",
        "outputId": "a1ac31af-d5a3-4512-de51-9273094a1863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37/37 [==============================] - 4s 107ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.66      0.55       172\n",
            "           1       0.85      0.77      0.81       626\n",
            "           2       0.85      0.82      0.84       371\n",
            "\n",
            "    accuracy                           0.77      1169\n",
            "   macro avg       0.72      0.75      0.73      1169\n",
            "weighted avg       0.79      0.77      0.78      1169\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = combined_model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXfiOnYIxA3n"
      },
      "source": [
        "## 3. Preguntas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zeMTWnbxDDK"
      },
      "source": [
        "1. ¿Cuáles son las diferencias en usar BERT como feature extraction y fine-tuning? ¿Qué argumento debemos modificar dentro del código para escoger entre las dos opciones?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDzrHnjdTvrO",
        "outputId": "9d471b7b-e5e0-457e-fc2e-5bfbf57ad4cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "print(f'{bert_model.trainable}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj0tNxdghbPR"
      },
      "source": [
        "2. ¿Hay presencia de sobreajuste?¿Porqué? ¿Qué podemos hacer para mejorar nuestros modelos?\n",
        "- Capas densas con menos neuronas, balance de clases, capas de dropout, ajuste del learning rate."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
